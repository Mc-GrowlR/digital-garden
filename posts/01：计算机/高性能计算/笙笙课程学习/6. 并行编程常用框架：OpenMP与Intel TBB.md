# 第 0 章 并发与并行

## 摩尔定律

## 并发与并行的区别


在不同的应用场景下对于两者的要求也不一样

## 英特尔开源的并行编程库 TBB  

安装：
``` shell
yay -S tbb
```

## 任务组

用一个任务组 `tbb::task_group` 启动多个任务，并在组线程中等待该任务组的任务全部执行完毕。

**与标准库的差别：** 一个任务不一定对应一个线程，如果任务数量超过 CPU 最大的线程数，会由 tbb 在用户层负责调度任务运行在预先分配好的线程，而不是由操作系统负责调度线程运行在多个物理核心。

## `paralle_invoke`



# 第一章

## 时间复杂度与工作复杂度

**时间复杂度：** 程序所用的总时间（重点）
**工作复杂度：** 程序所用的计算量（次要）
两个指标都是越低越好。**时间复杂度决定了快慢，工作复杂度决定了耗电量**。
两者关系：工作复杂度 = 时间复杂度 * 核心数量

并行的主要目的是降低时间复杂度，工作复杂度通常是不变的。甚至有牺牲工作复杂度换取时间复杂度的情形。
 
并行算法的复杂度取决于数据量 n, 还取决于线程数来能够 c, 比如 O（n/c）。
线程数超过了 cpu 核心数就无法再加速了。

## 并行映射

### parallel_for


在其参数内使用索引

两个接口，
采用第二种形式编译器就可能没法优化。

### `parallel_for_each`

在其参数内可以使用迭代器

### 二维区间上的 `for` 循环：`blocked_range2d`

## 三维空间上的 `for` 循环：`blocked_range3d`

# 第 3 章缩并与扫描

## 缩并（reduce）

串行缩进的时间复杂度为 `o(n)` , 工作复杂度为 `O（n）

## 改进的并行缩并（GPU）

可以用递归的模式，每次只使数据缩小一般，这样基本每次都可以看作并行的 `for` ，只需 log2（n）次并行 for 即可完成缩进
 

这种常用于核心数量很多，比如 GPU 上的缩并。

但是 `tbb::parallel_reduce` 因为是动态地分配线程，所以每次运行的结果可能不一样。

如果想保持运行结果一致：`parallel_deterministic_reduce`, 这个能保证每次的区间分配都一样。

### 并行缩并的额外好处：能够避免浮点误差，例如求平均值。


### 扫描

扫描和缩进差不多，只不过他会把求和的**中间结果存到数组里去**

串行扫描的时间复杂度为 O (n), 工作复杂度为 O (n+c),。

并行扫描的时间复杂度为 O（n/c+c）, 工作复杂度为 O (n+c)

### 改进的并行扫描（GPU）

改进后的并行扫描的时间复杂度为 O（logn）, 工作复杂度为 O (nlogn)。

并行虽然降低了时间复杂度，但是以提升工作复杂度为代价

### 扫描函数：`parallel_scan`

# 第 3 章性能测试

## 测试所花费时间：`tbb::tick_count::now()`

包含 `tbb/tick_count,h` 头文件

## 性能评价

**公式：** 加速比 = 串行用时 / 并行用时
**理性加速比：** 应为核心数量

## 专业的性能测试框架：`Google benchmark`

只需要将要测试的代码放在
``` cpp
for (auto _:bm)
```
里面即可，他会自动决定要重复多少次，保证结果是准确的，同时不浪费太多时间
### 运行结果

`BENCHMARK_MAIN` 自动生成一个 `main` 函数，从而生成一个可执行文件供用户运行。运行后会得到测试的结果并打印到终端上

### 命令行参数

可以接受命令行参数

### CMake 中使用：作为子模块

# 第 4 章任务域与嵌套

## 任务域：`tbb::task_arena`

使用 `tbb::task_arena` 声明一个对象，然后再利用对象使用 `execute()` 方法来包裹任务。

其中也可以显式地指定使用几个线程在声明对象时在对象名后加括号，括号内是线程数参数。

任务域作用：指定使用几个线程

## 嵌套 `for` 循环

嵌套 for 容易造成死锁。

### 死锁问题的原因
因为 TBB 使用了**工作窃取法**来分配任务：当一个线程 t1 做完自己队列里全部的工作时，会从另一个工作中线程 t2 的队列里取出任务，以免 t1 闲置浪费时间。
因此内部 for 循环有可能“窃取”到另一个外部 for 循环的任务，从而导致 `mutex` 被重复上锁。

### 解决方案

#### 1. 用标准库的 `std::recusive_mutex`
包含头文件mutex
#### 2 . 创建另一个任务域，这样不同域之间就不会窃取工作

#### 3. 同一个任务域，但用 `isolate` 隔离，禁止其内部的工作被窃取（推荐）
`tbb::this_task_arena::isolate()` 

# 第 5 章任务分配

##  问题 ：如何在并行环境下如何均匀分配任务到每个线程

### 解决 1： 线程数量超过 CPU 核心数量，让系统调度保证各个核心始终饱和。

缺点：操作系统轮换是有代价的（性能损耗），而且有可能线程之间也会频繁切换造成性能损耗
线程数量太多可能造成调度的 `overhead`

### 解决 2：线程数量不变，但是用一个队列分发和认领任务

每个线程空闲时会不断地从那个队列里取出数据，即“认领任务”。

这种技术又称为线程池（thread pool），避免了线程需要保存上下文的开销。但是需要我们管理一个任务队列，而且要是线程安全的队列。

### 解决 3：每个线程一个任务队列，做完本职工作后可以认领其他线程的任务。
即“工作窃取法”

### 解决 4：随机分配法（通过哈希函数或线性函数）

队列的实现较复杂且需要同步机制，还是有一定的 `overhead`，因此另一种神奇的解法是：

GPU 上称为**网格跨步循环（grid-stride loop）**

如果做的是渲染器，推荐使用 `sobol` 算法：[SOBOL - The Sobol Quasirandom Sequence](https://people.math.sc.edu/Burkardt/m_src/sobol/sobol.html)

## `tbb::static_partitioner`: 指定区间的粒度

缺点：用于循环提不均匀的情况效果不好

## `tbb::simple_partitioner`: 指定区间粒度

用于循环体不均匀的情况效果很好
缺点：粒度为 1 太细了效果不好
## `tbb::auto_partitioner` (默认)
自动根据 `lambda` 中函数的执行时间判断采用和中分配方法。

以上三种都是可以作为参数传入 `execute` 方法

## `tbb::affinity_partitioner` 记录历史，下次根据经验自动负载均衡。

这个不能作为参数直接传入，而是需要先创建对象，再将对象作为参数传入。

## `tbb::this_task_arena::max_concurrency()` 可以获取当前的线程数

# 第 6 章并发容器

## 不连续的 `tbb::concurrent_vector`

`std::vector` 造成指针失效的根本原因在于他必须保证内存是**连续的**，从而不得不在扩容时移动元素。

 `tbb::concurrent_vector`，这个不保证元素在内存中是连续的。换来的有点是 `push_back` 进去的元素，扩容时不需要移动位置，从而**指针和迭代器不会失效**。
 同时他的 `push_back` 会额外返回一个迭代器，指向刚刚插入的对象。

### `grow_by` 一次性扩容一定大小

`push_back` 一次只能推入一个元素。

而 `grow_by(n)` 则可以一次扩充 n 个元素。同样也是返回一个迭代器，之后可以通过迭代器的 `++` 运算符依次访问连续的 n 个元素，`*` 运算符访问当前指向的元素。

### 可安全地被多线程并发访问

`tbb::concurrent_vector` 还是一个**多线程安全的容器**，能够被多个线程同时并发地 `grow_by` 或 `push_back` 而不出错。

而 `std::vector` 只有只读的 `.size()` 和 `[]` 运算符是安全的，且不能和写入的 `push_back` 等一起用，否则需要用读写锁保护。

### 缺点
1. 不建议通过索引随机访问
   因为 `tbb::concurrent_vector`**内存不连续**的特点，通过索引访问，比通过迭代器访问的效率低一些。
2. 同样 `*(it+i)` 这样需要迭代器跨步访问的也不推荐

## `parallel_for` 也支持迭代器
`tbb::blocked_range` 的参数不一定是 `size_t`，也可以是迭代器表示的区间。
这样 `lambda` 体内 `r` 的 `begin` 和 `end` 也会返回 `tbb::concurrent_vector` 的迭代器类型。

## TBB 中的其他并发容器

# 第 7 章并行筛选

## 筛选（filter）

利用 `vector` 的 `push_back` 筛选数据

### 并行筛选 1

利用多线程安全的 `tbb::concurrent_vector` 动态追加数据基本没有加速。

加速比非常小。

### 并行筛选 2
先推到线程局部（thread-local）的 vector 最后一次性推入到 `tbb::concurrent_vector` 可以避免在 `tbb::concurrent_vector` 上产生锁竞争。

### 并行筛选 3
线程局部的 vector 调用 `reserve` 预先分配一定内存避免 `push_back` 反复扩容时分段式增长同时利用标准库的 `std::copy` 模板简化了代码

### 并行筛选 4
如果需要筛选后的数据是连续的，即 a 是个 `std::vector` 这是就需要用 `mutex` 锁定，避免数据竞争。
`back_inserter()` 的功能：

### 并行筛选 5
先对 a 预留一定的内存，避免频繁扩容影响性能。

### 并行筛选 6

使用 `tbb::spin_mutex` 代替 `std::mutex`。`tbb::spin_mutex` 基于硬件原子指令，会让 cpu 陷入循环等待，而不是像 mutex（操作系统提供调度）会让线程进入休眠状态的等待。

如果上锁区域较小，可以用轻量级的 spin_mutex。若上锁的区域很大，则循环等待只会浪费 CPU 时间。

还有 `tbb::spin_rw_mutex` 对标 `std::shared_mutex`

### 并行筛选 7
彻底避免了互斥量，完全通过预先准备好的大小，配合 `atomic` 递增索引批量写入。

### 并行筛选 8 （不推荐）


### 并行筛选 9（GPU）

# 分治与排序

任务划分的够细时，转为串行，环节调度负载

## 标准库提供的排序

包含头文件 `algorithm`

`sort()`

## 快速排序

## 并行快速排序

## `tbb::parallel_sort` 与 `std::sort` 功能差不多

但是更快

## 分治法
大问题一分为二变成小问题，分派到各个 CPU 核心上，问题足够小时直接串行求解。

也可以通过 `parallel_invoke` 分治实现

# 流水线并行

### filter 参数

### 流水线的利弊

## 各种并行模式

数据之间有依赖用流水线并行模式。

